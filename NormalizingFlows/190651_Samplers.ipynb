{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "190651_Samplers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First 3 parts of Assignment"
      ],
      "metadata": {
        "id": "sWKu3R-7ruq5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Jhz0_viMzBgN"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "tfd = tfp.distributions\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-1<br>\n",
        "Sampling the source Distribution"
      ],
      "metadata": {
        "id": "DCwGKKsf0FmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uniformSampler(support, dims):\n",
        "  '''\n",
        "  support is a list which contains info of support of distribution\n",
        "  dims : dimension of r.v\n",
        "  '''\n",
        "  low = []\n",
        "  high = []\n",
        "  for i in range(dims):\n",
        "    low.append(support[0])\n",
        "    high.append(support[1])\n",
        "\n",
        "  U = tfd.Uniform(low = low,high = high)\n",
        "  IndependentUniform = tfd.Independent(U, reinterpreted_batch_ndims=1)\n",
        "\n",
        "  return IndependentUniform"
      ],
      "metadata": {
        "id": "_AXuPDMV1D4-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler = uniformSampler([1,2],2)"
      ],
      "metadata": {
        "id": "KF7Te2Rl3LCN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampler.sample(1).numpy().squeeze()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VkPAlFzfMUd",
        "outputId": "561265fc-881b-43af-ec0c-c15344a0e8ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.2342336, 1.2992909], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-2<br>\n",
        "Sampling the target distribution using GMM"
      ],
      "metadata": {
        "id": "bLiDxnOufGau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "loT7OpMefw_6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GMMsampler(pi,mus,sigmas):\n",
        "  '''\n",
        "  pi : probabilities of hidden variables\n",
        "  mus : means of clusters\n",
        "  sigmas : std of clusters\n",
        "  '''\n",
        "  \n",
        "  gmm = tfd.Mixture(\n",
        "    cat = tfd.Categorical(probs = pi),\n",
        "    components = [tfd.MultivariateNormalDiag(loc = mus[i], scale_diag = sigmas[i]) for i in range(mus.shape[0])] )\n",
        "  \n",
        "  return gmm"
      ],
      "metadata": {
        "id": "hoTodfkejDau"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi = np.array([0.3,0.7]) # probabilities of hidden variables\n",
        "mus = np.array([[2.,3.],[1.,4.]])\n",
        "sigmas = np.array([[1.,1.],[1.,2.]])"
      ],
      "metadata": {
        "id": "1RDc-e7I3SfX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmmSampler = GMMsampler(pi,mus,sigmas)"
      ],
      "metadata": {
        "id": "MDL_5g-AjwH_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmmSampler.sample().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2YVN4KFj3gF",
        "outputId": "be2b5fe2-bad5-48ea-e784-d36e974d6537"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.21769471, 6.19134892])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-3<br>\n",
        "Sampling using Normalising Flows(RNVP)<br>\n",
        "$$x_1 = u_1$$\n",
        "$$x_2 = u_2.\\sigma(u_1) + \\mu(u_1)$$"
      ],
      "metadata": {
        "id": "yhfbStZdkInU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(layers.Layer):\n",
        "\n",
        "    \"\"\"\n",
        "    Neural Network Architecture for calcualting s and t for Real-NVP\n",
        "    \n",
        "    :param input_shape: shape of the data coming in the layer\n",
        "    :param hidden_units: Python list-like of non-negative integers, specifying the number of units in each hidden layer.\n",
        "    :param activation: Activation of the hidden units\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape, n_hidden=[64,64], activation=\"relu\"):\n",
        "        super(NN, self).__init__(name=\"nn\")\n",
        "        layer_list = []\n",
        "        for n in n_hidden:\n",
        "            layer_list.append(layers.Dense(n, activation=activation))\n",
        "        self.layer_list = layer_list\n",
        "        self.log_s_layer = layers.Dense(input_shape, activation=\"tanh\", name='log_s')\n",
        "        self.t_layer = layers.Dense(input_shape, name='t')\n",
        "\n",
        "    def call(self, x):\n",
        "        y = x\n",
        "        for layer in self.layer_list:\n",
        "            y = layer(y)\n",
        "        log_s = self.log_s_layer(y)\n",
        "        t = self.t_layer(y)\n",
        "        return log_s, t"
      ],
      "metadata": {
        "id": "bxesPxpPT90Q"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuralNet = NN(1)"
      ],
      "metadata": {
        "id": "RALr4tnwd6kr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NFsampler(neuralNet,n):\n",
        "  '''\n",
        "  n: number of samples\n",
        "  neuralNet: neural network to get scaling and shifting factors\n",
        "  '''\n",
        "  \n",
        "  samples = []\n",
        "  for i in range(n):\n",
        "    U = ((uniformSampler([0,1], 2)).sample()).numpy()\n",
        "    u1,u2 = tf.split(U,2)\n",
        "    u1 = u1[...,np.newaxis]\n",
        "    u2 = u2[...,np.newaxis]\n",
        "    x1 = u1\n",
        "    log_s, t = neuralNet.call(u1)\n",
        "    x2 = tf.exp(log_s)*U[1] + t\n",
        "    samples.append([x1,x2])\n",
        "\n",
        "  samples = np.asarray(samples).squeeze()\n",
        "  \n",
        "  return samples "
      ],
      "metadata": {
        "id": "FUVUU6-FhtAP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = NFsampler(neuralNet,5)"
      ],
      "metadata": {
        "id": "5LzkrlT3YEW_"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in samples:\n",
        "  print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T-eKL2cZNYi",
        "outputId": "d029b59b-cb4e-4bd1-cb71-577534ba7d93"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.88382375 0.47093803]\n",
            "[0.6752194  0.34654188]\n",
            "[0.19863641 0.6859551 ]\n",
            "[0.42696834 0.10517609]\n",
            "[0.06880498 0.04574803]\n"
          ]
        }
      ]
    }
  ]
}